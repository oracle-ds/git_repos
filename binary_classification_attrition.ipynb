{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oracle Data Science service sample notebook.\n",
    "\n",
    "Copyright 2020, 2022 Oracle, Inc. All rights reserved. Licensed under the [Universal Permissive License v 1.0](https://oss.oracle.com/licenses/upl).\n",
    "\n",
    "---\n",
    "\n",
    "# <font color=\"red\">Binary Classification for Predicting Employee Attrition with `ADS`</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=\"teal\">Oracle Cloud Infrastructure Data Science Service.</font></p>\n",
    "\n",
    "---\n",
    "\n",
    "# Overview:\n",
    "\n",
    "In this notebook, an employee attrition dataset is used. You start by doing an exploratory data analysis (EDA) to understand the data. Then a model is trained using `sklearn`. The model is used to make predictions and evaluate the model to determine how well it generalizes to new data. Then you use machine learning explainability (MLX) to understand the global and local model behavior. You do all of this using the Oracle Accelerated Data Science (`ADS`) library.\n",
    "\n",
    "---\n",
    "\n",
    "## Contents:\n",
    "\n",
    "- <a href='#setup'>Setting Up</a>\n",
    "- <a href='#data'>Opening and Visualizing Datasets using `ADS`</a>\n",
    "   - <a href='#binaryclassifition'>Binary Classification</a>\n",
    "   - <a href='#data'>The Dataset</a>\n",
    "   - <a href='#viz'>Visualizing the Dataset</a>\n",
    "   - <a href='#eda'>Exploratory Data Analysis</a> \n",
    "   - <a href='#trans'>Getting and Applying Transformation Recommendations</a> \n",
    "- <a href='#model'>Building and Visualizing Models</a>\n",
    "- <a href='#eval'>Evaluating Models Using `ADSEvaluator`</a>\n",
    "- <a href='#explainations'>Explaining How Models Work Using `ADSExplainer`</a>\n",
    "   - <a href='#adsexplainer'>Using the `ADSExplainer` Class</a>\n",
    "   - <a href='#global'>Generating Global Explanations</a>\n",
    "   - <a href='#show'>Showing What the Model Has Learned</a>\n",
    "        - <a href='#show'>Using `ADSExplainer` for a Custom Model</a>\n",
    "        - <a href='#pdp'>Feature Dependence Explanations</a>   \n",
    "   - <a href='#localexplanations'>Generating Local Explanations</a>\n",
    "- <a href='#ref'>References</a>          \n",
    "\n",
    "---\n",
    "\n",
    "**Important:**\n",
    "\n",
    "Placeholder text for required values are surrounded by angle brackets that must be removed when adding the indicated content. For example, when adding a database name to `database_name = \"<database_name>\"` would become `database_name = \"production\"`.\n",
    "\n",
    "---\n",
    "\n",
    "<font color=\"gray\">\n",
    "Datasets are provided as a convenience.  Datasets are considered third-party content and are not considered materials \n",
    "under your agreement with Oracle.\n",
    "\n",
    "You can access the `orcl_attrition` dataset license [here](https://oss.oracle.com/licenses/upl).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "# Setting Up\n",
    "\n",
    "Import everything necessary to this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.catalog.project import ProjectCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "from ads.common.data import ADSData\n",
    "from ads.common.model import ADSModel\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from collections import defaultdict\n",
    "from os.path import expanduser\n",
    "from os.path import join\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Opening and Visualizing Datasets using `ADS`\n",
    "\n",
    "<a id='binaryclassifition'></a>\n",
    "## Binary Classification\n",
    "\n",
    "Binary classification is a technique of classifying observations into one of two groups. In this notebook, the two groups are those employees that will leave the organization and those that will not. \n",
    "\n",
    "Given the features in the data, the model determines the optimal criteria for classifying an observation as leaving or not leaving. This optimization is based on the training data. However, some of the data to test the model's preformance is reserved. Models can overfit on the training data, that is learn the noise in a dataset, and then it won't do a good job at predicting the results on new data (test data). Since you already know the truth for the data in the training dataset, you are really interested in how well it performs on the test data.\n",
    "\n",
    "<a id='data'></a>\n",
    "## The Dataset\n",
    "\n",
    "This is a fictional dataset and contains 1,470 rows. There are 36 features with 22 ordinal features, 11 categorical features, and 3 constant values. The features include basic demographic information, compensation level, job characteristics, job satisfaction, and employee performance metrics. The data is not balanced as fewer employees leave than stay.\n",
    "\n",
    "The first step is to load in the dataset. To do this the `DatasetFactory` singleton object is used. It is part of the `ADS` library and is a powerful class to work with datasets from different sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_path = join(\"/\", \"opt\", \"notebooks\", \"ads-examples\", \"oracle_data\", \"orcl_attrition.csv\")\n",
    "\n",
    "ds = DatasetFactory.open(\n",
    "      attrition_path,\n",
    "      target=\"Attrition\").set_positive_class('Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='viz'></a>\n",
    "## Visualizing the Dataset\n",
    "\n",
    "The `.feature_plot()` method can be applied to create the visualization on a dataset sample to give an understanding of the nature of the data in feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Attrition'].ads.feature_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Age'].ads.feature_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['EducationalLevel'].ads.feature_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `show_corr()` method to visualize correlations between features, even when the features are different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.show_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "The `DatasetFactory` does more than just open data from various sources. It profiles the data, determines their data types, and uses sampling to prepare visualizations. The `type_of_target` method provides information about the target, which is the value that is going to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.type_of_target()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show_in_notebook()` method is used in many classes within `ADS`. It makes a best effort to display information that is meaningful to a data scientist about the object. In the next cell, it is applied to the target variable and it shows the relative frequency of the classes in the data. Since the target is `Attrition`, False means people who did not leave and True are people that do. It shows that the data is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.target.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trans'></a>\n",
    "## Getting and Applying Transformation Recommendations\n",
    "\n",
    "`ADS` can help with feature engineering by transform datasets. For example, it can fix class imbalance by up or downsampling. There are many transforms that `ADS` can also apply. You can have `ADS` perform an analysis of the data and automatically perform the transformations that it thinks would improve the model. This is done using the `auto_transform()` method. The `suggest_recommendations()` method allows you to explore the suggested transforms using the notebook's UI and select the transformations that you want it to make.\n",
    "\n",
    "All `ADS` datasets are immutable, any transforms that are applied result in a new dataset. In this example, the notebook performs automatic transformations on the data and it also fixes the class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ds = ds.auto_transform(fix_imbalance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "# Building and Visualizing Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ADS` also provides the ability to split a dataset into training and testing datasets using the `train_test_split` method and `train` to train a set of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = transformed_ds.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ADS` is agnostic to the source of the model as it takes advantage of duck typing, something that looks like a model and walks like a model, is a model to `ADS`. \n",
    "\n",
    "Next, you build a `sklearn` random forest model, and then use it with `ADS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameLabelEncoder(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.label_encoders = defaultdict(LabelEncoder)\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for column in X.columns:\n",
    "            if X[column].dtype.name  in [\"object\", \"category\"]:\n",
    "                self.label_encoders[column] = OrdinalEncoder()\n",
    "                self.label_encoders[column].fit(X[column])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        for column, label_encoder in self.label_encoders.items():\n",
    "            X[column] = label_encoder.transform(X[column])\n",
    "        return X\n",
    "\n",
    "le = DataFrameLabelEncoder()\n",
    "X = le.fit_transform(train.X.copy())\n",
    "y = train.y.copy()\n",
    "\n",
    "sk_clf = RandomForestClassifier(random_state=42)\n",
    "sk_clf.fit(X, y)\n",
    "\n",
    "# Build an ADS model.\n",
    "my_model = ADSModel.from_estimator(make_pipeline(le, sk_clf), \n",
    "                                   name=sk_clf.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest accuracy on test data:\", my_model.score(test.X, test.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate another model to compare the random forest to, in this case, we can use the more simple `DecisionTreeClassifier` as a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state = 42)\n",
    "dt_clf.fit(X, y)\n",
    "\n",
    "my_other_model = ADSModel.from_estimator(make_pipeline(le, dt_clf), \n",
    "                                   name=dt_clf.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision tree accuracy on test data:\", my_other_model.score(test.X, test.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eval'></a>\n",
    "# Evaluating Models using `ADSEvaluator`\n",
    "\n",
    "One of the key advantages of `ADS` is the ability to quickly evaluate any models. `ADS` supports evaluating:\n",
    "\n",
    "- Regression\n",
    "- Binary classification\n",
    "- Multiclass classification\n",
    "\n",
    "`ADS` allows you to provide your own evaluation function (given `y_true` and `y_pred` series) for any esoteric calculation that you want to run.\n",
    "\n",
    "Next, you examine the plots that are commonly used to evaluate model performance. These include the precision-recall, ROC, lift, and gain plots. Each model under study is plotted together. This allows for easy comparison. In addition, the normalized confusion matrices are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ADSEvaluator(test, models=[my_model, my_other_model], \n",
    "                         training_data=train,\n",
    "                         show_full_name=True,\n",
    "                         positive_class=True)\n",
    "evaluator.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of common metrics that are used to assess the quality of a model. `ADS` provides a convenient method to compare the models and highlights the model with the highest score in each metric.\n",
    "\n",
    "Performance on training data doesn't tell you how the model performs on unseen data. You should look to performance on the `test` dataset to get an idea of which model is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary classification model can have one of four outcomes for each prediction. A true negative is an outcome where the model correctly predicts the negative case. For this example, that would be the case when the employee is predicted to leave. A false positive is when the model incorrectly predicts that an employee would stay and they do not. However, not all predictions may have the same importance. For example, a cancer test has a higher cost when it incorrectly says that a patient does not have cancer when they do. The `calculate_cost` method allows the cost to be computed for each model based on the cost of each class of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.calculate_cost(tn_weight=1, fp_weight=3, fn_weight=2, tp_weight=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='explanations'></a>\n",
    "# Explaining How Models Work Using `ADSExplainer`\n",
    "\n",
    "The remainder of this notebook demonstrates how you can use the `ADS` explanation module to help better understand the behavior of your trained model. First you create the required `ADS` explainer objects to then begin generating global and local explanations. \n",
    "\n",
    "Some useful terms for machine learning explainability (MLX):\n",
    "  - **Explainability**: The ability to explain the reasons behind an machine learning model’s prediction.\n",
    "  - **Interpretability**: The level at which a human can understand the explanation.\n",
    "  - **Global Explanations**: Understand the general behavior of a machine learning model as a whole.\n",
    "  - **Local Explanations**: Understand why the machine learning model made a specific prediction.\n",
    "  - **Model-Agnostic Explanations**: Explanations treat the machine learning model and feature pre-processing as a black-box, instead of using properties from the model to guide the explanation.\n",
    "\n",
    "The `ADS` explanation module provides interpretable, model-agnostic, and local and global explanations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adsexplainer'></a>\n",
    "## Using the `ADSExplainer` Class\n",
    "\n",
    "`ADS` provides a general explainer class, `ADSExplainer`, which is used to generate both global and local explanations for machine learning models. `ADSExplainer` takes as input the datasets used to train and evaluate the model (such as, train and test) and the model itself. Any type of model containing a `.predict_proba()` or `.predict()` method can be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model explainer class\n",
    "explainer = ADSExplainer(test, my_model)\n",
    "\n",
    "# let's created a global explainer\n",
    "global_explainer = explainer.global_explanation(provider=MLXGlobalExplainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='global'></a>\n",
    "## Generating Global Explanations\n",
    "\n",
    "Start with generating global explanations for the model. Using the `ADSExplainer` object, you can create a global explanation object to generate global model explanations. Oracle Labs global MLX is selected as the provider using the `MLXGlobalExplainer` object. Global explanation supports both feature importance explanations and feature dependence explanations, such as Partial Dependence Plots (PDP) and Individual Conditional Expectations (ICE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explainer.feature_importance_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the global feature importance explanation and visualize the top six features as a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = global_explainer.compute_feature_importance()\n",
    "importances.show_in_notebook(n_features=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize a detailed scatter plot to show the distribution of the importance measure and provides a sense of the variation in the data. Five features are plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.show_in_notebook(n_features=5, mode='detailed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed information used to generate the above plot is available with the `get_global_explanations` method. It returns an array of JSON structures. This displays the results for only one of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.get_global_explanation()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='show'></a>\n",
    "## Showing What the Model Has Learned\n",
    "\n",
    "It is great to have an expert with knowledge of what a model should do. However, this is often not available. Models sometimes learn different things than what an expert would speculate should be learned. Generally, models learn important relationships between the data. For many machine learning models, it is difficult or almost impossible to understand what the model has learned. The `ADSExplainer` provides a powerful set of tools that provides the data scientist insight into what a complex model is doing. It does this by building other models and performing simulations on the model's predictions. From this, the `ADSExplainer` learns what has been learned.\n",
    "\n",
    "When an explanation does not make sense, it does not mean the explanation is wrong. It is possible that the model has learned new relationships in the data. This allows MLX to be used to understand and debug the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='custom'></a>\n",
    "### Using `ADSExplainer` on the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_custom_model = ADSExplainer(test, my_other_model)\n",
    "fi = explainer_custom_model.global_explanation(\n",
    "    provider=MLXGlobalExplainer()).compute_feature_importance()\n",
    "fi.show_in_notebook(n_features=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pdp'></a>\n",
    "### Feature Dependence Explanations\n",
    "\n",
    "Next, you generate global explanations to visualize how different values for the important features interact with the target variable. This is done using PDP and ICE explanations. \n",
    "\n",
    "The next cell shows you how to learn more about the PDP and ICE techniques used in the `MLXGlobalExplainer`. This provides a description of the algorithm and how to interpret the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explainer.partial_dependence_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the PDP plot for the `OverTime` feature. From this you can see that if an employee does `Overtime`, they are more likely to leave the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.global_explanation().compute_partial_dependence(\"OverTime\")\n",
    "explanation.show_in_notebook(mode=\"pdp\", labels=[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ICE, the results for each sample can be seen for both the True and False cases (employee leaves or stays). This approach allows the data scientist to see the distribution of importance values. In this example, the output has been centered and pinned on its first prediction. Also, a median line is plotted to show the general trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.show_in_notebook(mode=\"ice\", centered=True, \n",
    "                               show_distribution=True, \n",
    "                               show_correlation_warning=True, \n",
    "                               show_median=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDP is able to consider the interaction between multiple variables. In theory, any level of interaction can be used though practically only two-way interaction can be plotted without a significant amount of compute so it is generally limited to two variables. In this example, the feature importance is determined between the `Age` and `JobRole` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjr_explanation = explainer.global_explanation().compute_partial_dependence(\n",
    "    ['Age', 'JobRole'])\n",
    "\n",
    "\n",
    "adjr_explanation.show_in_notebook(\n",
    "    show_distribution=True, show_correlation_warning=False, line_gap=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access to the raw data can be obtained by converting it to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjr_explanation.as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='localexplanations'></a>\n",
    "## Generating Local Explanations\n",
    "\n",
    "Global explanations inform the data scientist about the general trends in a model. They do not describe what is happening with a specific prediction. That is the role of local explanations. They are model-agnostic and provide insights into why a model made a specific prediction.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "local_explainer = explainer.local_explanation(provider=MLXLocalExplainer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a detailed summary about how local explanations work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_explainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select and display a sample to perform a local explanation on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y) = test.X.iloc[0:1], test.y.iloc[0:1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.local_explanation(\n",
    "    provider=MLXLocalExplainer()).explain(X, y).show_in_notebook(labels=[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "# References\n",
    "\n",
    "- [ADS Library Documentation](https://docs.cloud.oracle.com/en-us/iaas/tools/ads-sdk/latest/index.html)\n",
    "- [Data Science YouTube Videos](https://www.youtube.com/playlist?list=PLKCk3OyNwIzv6CWMhvqSB_8MLJIZdO80L)\n",
    "- [Interpretable Machine Learning ICE](https://christophm.github.io/interpretable-ml-book/ice.html)\n",
    "- [Interpretable Machine Learning PDP](https://christophm.github.io/interpretable-ml-book/pdp.html)\n",
    "- [OCI Data Science Documentation](https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm)\n",
    "- [Oracle Data & AI Blog](https://blogs.oracle.com/datascience/)\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:generalmachinelearningforcpusonpython3_7vy]",
   "language": "python",
   "name": "conda-env-generalmachinelearningforcpusonpython3_7vy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
